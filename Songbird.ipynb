{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Deep Learning Project\n",
    "\n",
    "**Group:** Songbird  \n",
    "**Members:** Charlotte de Vries, Jiazhen Tang, Paulo Zirlis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup block\n",
    "import os\n",
    "import time  # Added this because ConvergenceTimer needs it\n",
    "\n",
    "# --- 1. FORCE LEGACY KERAS (CRITICAL FOR ViT) ---\n",
    "# This must run before any other keras/tensorflow imports\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# --- 2. IMPORTS ---\n",
    "# We prioritize tensorflow.keras to ensure compatibility\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import transformers\n",
    "from transformers import TFAutoModelForImageClassification\n",
    "from transformers import TFViTModel\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 3. APPLY THE \"INPUT LAYER\" PATCH (CRITICAL FOR CNN) ---\n",
    "# This allows the Keras 2 InputLayer to accept the 'shape' argument\n",
    "# preventing the crash in your CNN code.\n",
    "\n",
    "OriginalInputLayer = layers.InputLayer\n",
    "\n",
    "class FriendlyInputLayer(OriginalInputLayer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # If 'shape' is used (Keras 3 style), swap it to 'input_shape' (Keras 2 style)\n",
    "        if 'shape' in kwargs and 'input_shape' not in kwargs:\n",
    "            kwargs['input_shape'] = kwargs.pop('shape')\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "# Overwrite the class in the 'layers' module so your code uses it automatically\n",
    "layers.InputLayer = FriendlyInputLayer\n",
    "tf.keras.layers.InputLayer = FriendlyInputLayer\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Setup timer\n",
    "class ConvergenceTimer(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        print(\"Training started...\")\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        self.end_time = time.time()\n",
    "        self.total_time = self.end_time - self.start_time\n",
    "        print(f\"\\nTraining finished.\")\n",
    "        print(f\"Time to converge: {self.total_time:.2f} seconds ({self.total_time/60:.2f} minutes)\")\n",
    "\n",
    "\n",
    "print(\"Setup OK: Legacy mode enabled & InputLayer patched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### 1.1 Objective*\n",
    "\n",
    "Apply different deep learning architectures to the visual classification task of identifying brain tumors in MRI images and compare them based on accuracy and time to converge.\n",
    "\n",
    "\n",
    "### 1.2 Neural Network Architectures\n",
    "\n",
    "We will implement and compare the following architectures:\n",
    "- Custom Convolutional Neural Network (CNN) with keras sequential\n",
    "- Custom Residual Network (ResNet)\n",
    "- Pre-trained Residual Network (ResNet50)\n",
    "- Pre-trained Residual Network (ResNet50) with fine-tuning\n",
    "- Pre-trained Visual Transformer (ViT)\n",
    "- Pre-trained Visual Transformer (ViT) with fine-tuning\n",
    "\n",
    "\n",
    "### 1.3 Dataset Description\n",
    "\n",
    "The dataset includes high-resolution CT and MRI images captured from multiple patients, with each image labeled with the corresponding tumor type (e.g., glioma, meningioma, etc.). For this project we will focus solely on the **MRI** images for simplicity. The dataset's creator collected these data from different sources to assist researchers and healthcare professionals in developing AI models for the automatic detection, classification, and segmentation of brain tumors.\n",
    "\n",
    "The images are divided as follows:\n",
    "- Healty images: 2000\n",
    "- Tumor images: 3000\n",
    "    - Meningioma: 1112\n",
    "    - Glioma: 672\n",
    "    - Pituitary: 629\n",
    "    - Tumor: 587\n",
    "- **Total of images:** 5000\n",
    "\n",
    "Source: [Brain tumor multimodal image (Kaggle)](https://www.kaggle.com/datasets/murtozalikhon/brain-tumor-multimodal-image-ct-and-mri/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 2.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "# 1. SETUP PATHS\n",
    "dataset_path = 'Data/Brain Tumor MRI images'\n",
    "\n",
    "print(f\"Checking contents of: {dataset_path}\")\n",
    "try:\n",
    "    items = os.listdir(dataset_path)\n",
    "    print(\"Found these items:\", items)\n",
    "except:\n",
    "    print(\"Error: The dataset_path does not exist.\")\n",
    "\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "\n",
    "# Get list of all folders in the main directory\n",
    "all_items = os.listdir(dataset_path)\n",
    "\n",
    "for item in all_items:\n",
    "    item_path = os.path.join(dataset_path, item)\n",
    "    \n",
    "    # We only care if it's a folder (directory)\n",
    "    if os.path.isdir(item_path):\n",
    "        \n",
    "        # --- CASE A: The 'Healthy' Folder ---\n",
    "        if 'healthy' in item.lower():\n",
    "            print(f\"Processing Healthy folder: {item}\")\n",
    "            for filename in os.listdir(item_path):\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "                    filepaths.append(os.path.join(item_path, filename))\n",
    "                    labels.append('Healthy')\n",
    "                    \n",
    "        # --- CASE B: The 'Tumour' Folder (Anything that isn't Healthy) ---\n",
    "        else:\n",
    "            print(f\"Processing Tumour folder: {item}\")\n",
    "            for filename in os.listdir(item_path):\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "                    full_path = os.path.join(item_path, filename)\n",
    "                    name_lower = filename.lower()\n",
    "                    \n",
    "                    # Determine Subtype based on filename\n",
    "                    if 'glioma' in name_lower:\n",
    "                        label = 'Glioma'\n",
    "                    elif 'meningioma' in name_lower:\n",
    "                        label = 'Meningioma'\n",
    "                    elif 'pituitary' in name_lower:\n",
    "                        label = 'Pituitary'\n",
    "                    else:\n",
    "                        label = 'Tumor (Unspecified)' \n",
    "                    \n",
    "                    filepaths.append(full_path)\n",
    "                    labels.append(label)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "\n",
    "# Check results\n",
    "print(f\"Total images found: {len(df)}\")\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 2.2 Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identify the majority class count\n",
    "max_count = df['label'].value_counts().max()\n",
    "print(f\"Target count per class: {max_count}\")\n",
    "\n",
    "# 2. Separate the dataframe by class\n",
    "groups = df.groupby('label')\n",
    "\n",
    "# 3. Create a list to hold the balanced dataframes\n",
    "balanced_dfs = []\n",
    "\n",
    "for label, group_df in groups:\n",
    "    # If this group is smaller than the max, oversample it\n",
    "    if len(group_df) < max_count:\n",
    "        \n",
    "        # Resample logic:\n",
    "        # replace=True: This allows duplication (essential for oversampling)\n",
    "        # n_samples=max_count: Target number of samples\n",
    "        oversampled_group = resample(group_df, \n",
    "                                     replace=True, \n",
    "                                     n_samples=max_count, \n",
    "                                     random_state=42)\n",
    "        balanced_dfs.append(oversampled_group)\n",
    "        print(f\"Oversampled {label} from {len(group_df)} to {len(oversampled_group)}\")\n",
    "        \n",
    "    else:\n",
    "        # If it's the majority class (Healthy), just keep it as is\n",
    "        balanced_dfs.append(group_df)\n",
    "        print(f\"Kept {label} at {len(group_df)}\")\n",
    "\n",
    "# 4. Concatenate all back into one DataFrame\n",
    "df_balanced = pd.concat(balanced_dfs).reset_index(drop=True)\n",
    "\n",
    "# 5. Shuffle the dataset so classes aren't clustered together\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 6. Verify the new counts\n",
    "print(\"\\nNew Label Distribution:\")\n",
    "print(df_balanced['label'].value_counts())\n",
    "\n",
    "# 7. Update your main df variable\n",
    "df = df_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### 2.3 Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split: 80% Train, 20% Test (using stratify to keep classes balanced)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42, stratify=df['label'])\n",
    "\n",
    "# 3. Split Train again to get Validation set (e.g. 10% of total)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.125, shuffle=True, random_state=42, stratify=train_df['label'])\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Val size:   {len(val_df)}\")\n",
    "print(f\"Test size:  {len(test_df)}\")\n",
    "\n",
    "# 4. Visualize to confirm labels are correct\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Get a random sample to check\n",
    "sample_df = df.sample(10)\n",
    "\n",
    "for i, (index, row) in enumerate(sample_df.iterrows()):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    img = mpimg.imread(row['filepath'])\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"{row['label']}\\n{os.path.basename(row['filepath'])[:10]}...\", fontsize=9) # Show label + part of filename\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### 2.4 Build Keras generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Images to correct format\n",
    "\n",
    "# 1. Define image size and batch size\n",
    "IMG_SIZE = (256, 256) \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 2. Create ImageDataGenerators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen   = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 3. Build generators FROM DATAFRAMES\n",
    "train_gen = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 3. Custom Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The Convolutional Neural Network (CNN) model designed for this project consists of four convolutional blocks followed by a final block with pooling, dropout and fully connected layers. Each convolutional block has a convolution layer, batch normalization, activation function (ReLU) and max pooling. Early stopping was added to control for overfitting and underfitting. Batch normalization was used to improve training speed and stability. Dropout was included in the final block to further prevent overfitting. The model was compiled with the Adam optimizer, categorical cross-entropy loss function, and accuracy as the evaluation metric.\n",
    "\n",
    "<br>\n",
    "\n",
    "### 3.1 CNN Architecture\n",
    "\n",
    "**Input and Data Augmentation**\n",
    "- Input layer: shape (256, 256, 1)\n",
    "- Data Augmentation: Random rotations and horizontal flips\n",
    "\n",
    "**First Convolutional Block**\n",
    "- Conv2d layer: 32 filters, 3x3 kernel, stride of 1, same padding\n",
    "- Batch Normalization\n",
    "- ReLU Activation\n",
    "- MaxPooling2d layer: 2x2 pool size, stride of 2.\n",
    "\n",
    "**Other Convolutional Blocks**\n",
    "- same as the first block but with increasing number of filters (64, 128, 256)\n",
    "\n",
    "**Classifier Head**\n",
    "- Global Average Pooling layer\n",
    "- Dense layer: 64 units, ReLU activation\n",
    "- Dropout layer: 0.3 dropout rate\n",
    "- Dense layer: 5 units (nÂº of classes), Softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN Architecture\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Custom CNN\n",
    "CNN = keras.Sequential([\n",
    "    \n",
    "    # Input\n",
    "    layers.InputLayer(shape=[256, 256, 1]),\n",
    "    \n",
    "    # Data Augmentation\n",
    "    layers.RandomFlip(\"horizontal\"), # flip images horizontally\n",
    "    layers.RandomRotation(0.1),      # rotate images randomly by 10%\n",
    "\n",
    "\n",
    "    # 1st Convolutional Block\n",
    "    layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # 2nd Convolutional Block\n",
    "    layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # 3rd Convolutional Block\n",
    "    layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # 4th Convolutional Block\n",
    "    layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # 5th Convolutional Block\n",
    "    layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.SpatialDropout2D(0.2),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # 6th Convolutional Block\n",
    "    layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.SpatialDropout2D(0.2),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # Classifier Head\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(units=128),\n",
    "    layers.Dense(units=64),\n",
    "    layers.Dense(units=5, activation='softmax')  # 5 classes\n",
    "])\n",
    "\n",
    "CNN.summary()\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "CNN.compile(\n",
    "    optimizer = Adam(0.001),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 3.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ============== Callbacks ==============\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta = 0.001,\n",
    "    patience = 15,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "# Reduce LR on plateau\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,       # Reduce LR by 80% when stuck\n",
    "    patience=5,       # Wait 5 epochs before reducing\n",
    "    min_lr=1e-6,      \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_CNN.keras',    # Naming the file\n",
    "    monitor='val_accuracy',       # What to monitor\n",
    "    mode='max',                   # 'max' for accuracy, 'min' for loss\n",
    "    save_best_only=True,          \n",
    "    verbose=0                     # Print a message when saving\n",
    ")\n",
    "\n",
    "# Timer\n",
    "callback_timer = ConvergenceTimer()\n",
    "\n",
    "\n",
    "\n",
    "### ============== Training ==============\n",
    "\n",
    "# Fit the model\n",
    "hist_CNN = CNN.fit(\n",
    "    train_gen,\n",
    "    validation_data = val_gen,\n",
    "    batch_size = 32,\n",
    "    epochs = 30,\n",
    "    callbacks = [early_stopping, lr_scheduler, checkpoint, callback_timer],\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### 3.3 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ============== Evaluation ==============\n",
    "\n",
    "# Loss\n",
    "plt.plot(hist_CNN.history['loss'], label='train_loss')\n",
    "plt.plot(hist_CNN.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "plt.plot(hist_CNN.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(hist_CNN.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### 3.4 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy_CNN = CNN.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## 2.2 Residual Network\n",
    "3 ResNet models:\n",
    "- ResNet from scratch\n",
    "- ResNet pretrained without finetuning\n",
    "- ResNet pretrained with finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### **ResNet from scratch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "#### 1. Preprocessing data\n",
    "For fast training and less overfitting the inputsize is (128, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Images to correct format\n",
    "\n",
    "# 1. Define image size and batch size\n",
    "IMG_SIZE = (128, 128) \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 2. Create ImageDataGenerators\n",
    "train_rn_scratch_ = ImageDataGenerator(rescale=1./255)\n",
    "val_rn_scratch_  = ImageDataGenerator(rescale=1./255)\n",
    "test_rn_scratch_  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 3. Build generators FROM DATAFRAMES\n",
    "train_rn_scratch = train_rn_scratch_.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_rn_scratch = val_rn_scratch_.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_rn_scratch = test_rn_scratch_.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "#### 2. Create ResNet block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(x, filters, stride=1):\n",
    "    shortcut = x\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, strides=stride, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if stride != 1 or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=stride, padding=\"same\")(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "#### 3. Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    data_augmentation = keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "    ])\n",
    "\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    x = layers.Conv2D(16, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = resnet_block(x, 16)\n",
    "    x = resnet_block(x, 16)\n",
    "\n",
    "    x = resnet_block(x, 32, stride=2)\n",
    "    x = resnet_block(x, 32)\n",
    "\n",
    "    x = resnet_block(x, 64, stride=2)\n",
    "    x = resnet_block(x, 64)\n",
    "\n",
    "    # x = resnet_block(x, 128, stride=2)\n",
    "    # x = resnet_block(x, 128)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=5\n",
    "\n",
    "model_rn_scratch = build_resnet(\n",
    "    input_shape=(128, 128, 1),\n",
    "    num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "#### 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta = 0.001,\n",
    "    patience = 20,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "# Checkpoint\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_ResNet.keras',    # Naming the file\n",
    "    monitor='val_accuracy',       # What to monitor\n",
    "    mode='max',                   # 'max' for accuracy, 'min' for loss\n",
    "    save_best_only=True,          \n",
    "    verbose=0                     # Print a message when saving\n",
    ")\n",
    "\n",
    "# Reduce learning rate when needed\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',    \n",
    "    factor=0.5,            # multiply learning rate with 0.5 if there is no enhancement\n",
    "    patience=3,            \n",
    "    verbose=1,            \n",
    "    min_lr=1e-6            \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile model\n",
    "model_rn_scratch.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "## Train model\n",
    "timer_callback_rn_scratch = ConvergenceTimer()\n",
    "\n",
    "history = model_rn_scratch.fit(\n",
    "    train_rn_scratch,\n",
    "    validation_data=val_rn_scratch,\n",
    "    epochs=25,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "#### 4. Visualize the performance on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_frame = pd.DataFrame(history_rn_scratch.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['accuracy', 'val_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "#### 5. Evaluate model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy_rn_scratch = model_rn_scratch.evaluate(test_rn_scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "#### **Pretrained ResNet without finetuning**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "#### 1. Preprocessing data\n",
    "For the pretrained ResNet-50 model the input should be the same as the ImageNet which is: (224, 224, 3). Therefore we make new train, validation and test sets so that it matches the input the pretrained model expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_rn_pretrained_ = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "val_rn_pretrained_ = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_rn_pretrained_ = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_rn_pretrained = train_rn_pretrained_.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_rn_pretrained = val_rn_pretrained_.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_rn_pretrained = test_rn_pretrained_.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "#### 2. Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "## pretrained base\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "base_model.trainable = False   # Freeze weights\n",
    "\n",
    "## attach head\n",
    "model_rn_pt = models.Sequential([\n",
    "\n",
    "    layers.RandomFlip(\"horizontal\"), # data augmentation\n",
    "    layers.RandomRotation(0.1),\n",
    "\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "#### 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "## Compile model\n",
    "model_rn_pt.compile(\n",
    "    optimizer=Adam(1e-3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "## Train model\n",
    "timer_callback_rn_pt = ConvergenceTimer() # keep track of training time\n",
    "\n",
    "history_rn_pt = model_rn_pt.fit(\n",
    "    train_rn_pretrained,\n",
    "    validation_data=val_rn_pretrained,\n",
    "    epochs=25,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "#### 4. Visualizing the loss and accuracy for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "plt.plot(history_c5.history['loss'], label='train_loss')\n",
    "plt.plot(history_c5.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "plt.plot(history_c5.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history_c5.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### 4.2 ResNet **with finetuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "#### 1. Create the model with fine tuning\n",
    "Here we unfreeze the last 37 of 177 layers of the ResNet50 so that the weights of these layers can be trained. The first 140 layers stay froozen (untrained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze the first 140 layers \"freeze\"\n",
    "for layer in base_model.layers[:140]:\n",
    "    layer.trainable = False\n",
    "\n",
    "## attach head\n",
    "model_rn_pt_finetuned = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "#### 2. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile model\n",
    "model_rn_pt_finetuned.compile(\n",
    "    optimizer=Adam(1e-5),    \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "## Train model\n",
    "timer_callback_rn_pt_finetuned = ConvergenceTimer()\n",
    "\n",
    "history_rn_pt_finetuned = model_rn_pt_finetuned.fit(\n",
    "    train_rn_pretrained,\n",
    "    validation_data=val_rn_pretrained,\n",
    "    epochs=10,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "#### 3. Visualize the performance after fine tuning for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "history_frame = pd.DataFrame(history_rn_pt_finetuned.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['accuracy', 'val_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "#### 4. Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy_rn_pt_finetuned = model_rn_pt_finetuned.evaluate(test_rn_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "## 5. Pre-trained Vision Transformer\n",
    "\n",
    "### 5.1 ViT **without finetuning**\n",
    "\n",
    "#### 5.1.1 Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup Generators with 'channels_first'\n",
    "# We add data_format='channels_first' to match the Hugging Face ViT requirements\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1,\n",
    "    data_format='channels_first'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    data_format='channels_first'\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Flow from DataFrame\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,  \n",
    "    data_format='channels_first'\n",
    ")\n",
    "\n",
    "print(\"Generators recreated with Channels First format.\")\n",
    "\n",
    "# 3. Now run the training code again\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=3, \n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "#### 5.1.2 Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ensure we know the number of classes (should be 5)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# 2. Load the ViT Base Model (86M Parameters)\n",
    "vit_id = \"google/vit-base-patch16-224\"\n",
    "\n",
    "vit = TFAutoModelForImageClassification.from_pretrained(\n",
    "    vit_id, \n",
    "    num_labels=num_classes, \n",
    "    ignore_mismatched_sizes=True,\n",
    "    use_safetensors=False\n",
    ")\n",
    "\n",
    "# 3. Define Optimizer and Loss (Using tf_keras to avoid version errors)\n",
    "# ViT requires a small learning rate (5e-5)\n",
    "optimizer = Adam(learning_rate=5e-5)\n",
    "loss = CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# 4. Compile the model\n",
    "# jit_compile=True will help speed up this heavy model on the GPU\n",
    "vit.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss=loss, \n",
    "    metrics=['accuracy'],\n",
    "    jit_compile=True \n",
    ")\n",
    "\n",
    "print(f\"Successfully loaded and compiled {vit_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "#### 5.1.3 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ViT = vit.fit(\n",
    "    train_generator,\n",
    "    epochs=10, \n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "### 5.2 ViT **with finetuning**\n",
    "\n",
    "- **Stage 1 (Frozen)**: Set backbone.trainable = False. Train for 5-10 epochs. \n",
    "- Goal: This forces the new layers to \"calm down\" and learn basic patterns without disturbing the Backbone. \n",
    "\n",
    "<br>\n",
    "\n",
    "- **Stage 2 (Unfrozen)**: Set backbone.trainable = True. Re-compile with 1e-5 LR. Train for 5 more epochs. \n",
    "- Goal: Now that the new layers are stable, you unfreeze the Backbone to let the whole team work together to perfect the results.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 5.2.1 Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvergenceTimer(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        print(\"Training started...\")\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        self.end_time = time.time()\n",
    "        self.total_time = self.end_time - self.start_time\n",
    "        print(f\"\\nTraining finished.\")\n",
    "        print(f\"Time to converge: {self.total_time:.2f} seconds ({self.total_time/60:.2f} minutes)\")\n",
    "\n",
    "timer_callback = ConvergenceTimer()\n",
    "\n",
    "# ==========================================\n",
    "# 2. BUILD MODEL (Fixed for Keras Graph)\n",
    "# ==========================================\n",
    "\n",
    "# Load Backbone \n",
    "backbone = TFViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "backbone.trainable = True \n",
    "\n",
    "# Create Input (Channels First)\n",
    "inputs = Input(shape=(3, 224, 224), name=\"input_image\")\n",
    "\n",
    "# --- FIX: WRAP BACKBONE IN LAMBDA ---\n",
    "# We must use a Lambda function to extract .last_hidden_state safely\n",
    "# so Keras can track the gradients.\n",
    "def get_vit_features(x):\n",
    "    return backbone(x).last_hidden_state\n",
    "\n",
    "x = layers.Lambda(get_vit_features)(inputs)\n",
    "# ------------------------------------\n",
    "\n",
    "x = x[:, 0, :] # Extract CLS Token\n",
    "\n",
    "# Custom Hidden Layers (Your architecture)\n",
    "x = layers.Dense(512, activation='relu', name=\"hidden_layer_1\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Dense(256, activation='relu', name=\"hidden_layer_2\")(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# Output Layer\n",
    "outputs = layers.Dense(num_classes, name=\"prediction_head\")(x)\n",
    "\n",
    "# Build Model\n",
    "fine_tuned_model = Model(inputs=inputs, outputs=outputs, name=\"ViT_With_Custom_Head\")\n",
    "\n",
    "# Compile\n",
    "optimizer = Adam(learning_rate=5e-5) # 1e-4 is often too high for ViT, 5e-5 is safer\n",
    "loss = CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "fine_tuned_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "fine_tuned_model.summary()\n",
    "\n",
    "# ==========================================\n",
    "# 3. DATA ADAPTER (Fix for Keras 3 Error)\n",
    "# ==========================================\n",
    "\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(None, 3, 224, 224), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32)\n",
    ")\n",
    "\n",
    "# Convert generators to tf.data.Dataset\n",
    "train_ds = tf.data.Dataset.from_generator(lambda: train_generator, output_signature=output_signature)\n",
    "val_ds = tf.data.Dataset.from_generator(lambda: val_generator, output_signature=output_signature)\n",
    "\n",
    "# Optimization\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Steps\n",
    "train_steps = len(train_df) // 32\n",
    "val_steps = len(val_df) // 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "#### 5.2.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. TRAIN WITH TIMING\n",
    "# ==========================================\n",
    "\n",
    "history_custom = fine_tuned_model.fit(\n",
    "    train_ds,\n",
    "    epochs=10, \n",
    "    validation_data=val_ds,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=val_steps,\n",
    "    # Add the timer callback here alongside early stopping\n",
    "    callbacks=[early_stopping, timer_callback] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "### 6.? ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Predictions\n",
    "print(\"Generating predictions...\")\n",
    "# 'model' is the variable name used in your model.fit() call above\n",
    "raw_predictions = model.predict(test_generator)\n",
    "\n",
    "# Check if the model output is a Hugging Face object (TFSequenceClassifierOutput) or a standard Keras Tensor\n",
    "# TFAutoModelForImageClassification usually returns an object where .logits contains the data\n",
    "if hasattr(raw_predictions, 'logits'):\n",
    "    logits = raw_predictions.logits\n",
    "else:\n",
    "    logits = raw_predictions\n",
    "\n",
    "# Convert probabilities/logits to class indices (e.g., [0, 2, 4, 1...])\n",
    "y_pred = np.argmax(logits, axis=1)\n",
    "\n",
    "# Get the true labels from the generator\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get Class Names (e.g., 'Glioma', 'Healthy', etc.)\n",
    "# We sort the keys to ensure they match the index order (0, 1, 2...)\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# 2. Create the Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# 3. Plot the Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_labels, \n",
    "            yticklabels=class_labels)\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=15)\n",
    "plt.ylabel('Actual Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 4. Print Metrics\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for comparing all models"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
