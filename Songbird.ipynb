{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0576f7e7",
   "metadata": {},
   "source": [
    "# Deep Learning Project\n",
    "\n",
    "**Group:** Songbird  \n",
    "**Members:** Charlotte de Vries, Jiazhen Tang, Paulo Zirlis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49aa099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup block (packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a25a0",
   "metadata": {},
   "source": [
    "## 1. Project Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd88b15",
   "metadata": {},
   "source": [
    "## 2. Dataset Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d54f74",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d75893",
   "metadata": {},
   "source": [
    "## 2. Neural Network Models\n",
    "### 2.1 Custom CNN\n",
    "Paulo\n",
    "\n",
    "The Convolutional Neural Network (CNN) model designed for this project mostly of multiple blocks of convolutional layers followed by pooling layers ending with fully connected layers at the end. Early stopping and dropout layers were added to control for overfitting and underfitting. Batch normalization was used to improve training speed and stability.\n",
    "\n",
    "The architecture is as follows:\n",
    "\n",
    "**Input and Data Augmentation**\n",
    "- Input layer: shape (256, 256, 1)\n",
    "- Data Augmentation: Random rotations and horizontal flips\n",
    "\n",
    "**First Convolutional Block**\n",
    "- Conv2d layer: 32 filters, 3x3 kernel, stride of 1, same padding\n",
    "- Batch Normalization\n",
    "- ReLU Activation\n",
    "- MaxPooling2d layer: 2x2 pool size, stride of 2.\n",
    "\n",
    "**Other Convolutional Blocks**\n",
    "- same as the first block but with increasing number of filters (64, 128, 256)\n",
    "\n",
    "**Head**\n",
    "- Flatten layer\n",
    "- Dense layer: 512 units, ReLU activation\n",
    "- Dropout layer: 0.3 dropout rate\n",
    "- Dense layer: 5 units (nÂº of classes), Softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN Architecture\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Custom CNN\n",
    "CNN = keras.Sequential([\n",
    "    \n",
    "    # Input\n",
    "    layers.InputLayer(input_shape=[256, 256, 1]),\n",
    "    \n",
    "    # Data Augmentation\n",
    "    preprocessing.RandomFlip(\"horizontal\"), # flip images horizontally\n",
    "    preprocessing.RandomRotation(0.1),      # rotate images randomly by 10%\n",
    "\n",
    "\n",
    "    # First Convolutional Block\n",
    "    layers.Conv2d(filters=32, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=1),\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    layers.Conv2d(filters=64, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=1),\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    layers.Conv2d(filters=128, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=1),\n",
    "\n",
    "    # Fourth Convolutional Block\n",
    "    layers.Conv2d(filters=256, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=1),\n",
    "\n",
    "    # Classifier Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=256, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(units=5, activation='softmax')  # 5 classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and Evaluate CNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d289f3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e215ed71",
   "metadata": {},
   "source": [
    "## 2.2 Pre-trained Residual Network\n",
    "Charlotte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for ResNet\n",
    "# hello"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b1086",
   "metadata": {},
   "source": [
    "## 2.3 Pre-trained Vision Transformer\n",
    "Jiazhen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for ViT"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
