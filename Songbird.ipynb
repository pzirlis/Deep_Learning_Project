{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Deep Learning Project\n",
    "\n",
    "**Group:** Songbird  \n",
    "**Members:** Charlotte de Vries, Jiazhen Tang, Paulo Zirlis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup block\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "print(\"Setup OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### 1.1 Objective*\n",
    "\n",
    "Apply different deep learning architectures to the visual classification task of identifying brain tumors in MRI images and compare them based on accuracy and time to converge.\n",
    "\n",
    "\n",
    "### 1.2 Neural Network Architectures\n",
    "\n",
    "We will implement and compare the following architectures:\n",
    "- Custom Convolutional Neural Network (CNN) with keras sequential\n",
    "- Custom Residual Network (ResNet)\n",
    "- Pre-trained Residual Network (ResNet50)\n",
    "- Pre-trained Residual Network (ResNet50) with fine-tuning\n",
    "- Pre-trained Visual Transformer (ViT)\n",
    "- Pre-trained Visual Transformer (ViT) with fine-tuning\n",
    "\n",
    "\n",
    "### 1.3 Dataset Description\n",
    "\n",
    "The dataset includes high-resolution CT and MRI images captured from multiple patients, with each image labeled with the corresponding tumor type (e.g., glioma, meningioma, etc.). For this project we will focus solely on the **MRI** images for simplicity. The dataset's creator collected these data from different sources to assist researchers and healthcare professionals in developing AI models for the automatic detection, classification, and segmentation of brain tumors.\n",
    "\n",
    "The images are divided as follows:\n",
    "- Healty images: 2000\n",
    "- Tumor images: 3000\n",
    "    - Meningioma: 1112\n",
    "    - Glioma: 672\n",
    "    - Pituitary: 629\n",
    "    - Tumor: 587\n",
    "- **Total of images:** 5000\n",
    "\n",
    "Source: [Brain tumor multimodal image (Kaggle)](https://www.kaggle.com/datasets/murtozalikhon/brain-tumor-multimodal-image-ct-and-mri/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 2.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "# 1. SETUP PATHS\n",
    "dataset_path = 'Data/Brain Tumor MRI images'\n",
    "\n",
    "print(f\"Checking contents of: {dataset_path}\")\n",
    "try:\n",
    "    items = os.listdir(dataset_path)\n",
    "    print(\"Found these items:\", items)\n",
    "except:\n",
    "    print(\"Error: The dataset_path does not exist.\")\n",
    "\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "\n",
    "# Get list of all folders in the main directory\n",
    "all_items = os.listdir(dataset_path)\n",
    "\n",
    "for item in all_items:\n",
    "    item_path = os.path.join(dataset_path, item)\n",
    "    \n",
    "    # We only care if it's a folder (directory)\n",
    "    if os.path.isdir(item_path):\n",
    "        \n",
    "        # --- CASE A: The 'Healthy' Folder ---\n",
    "        if 'healthy' in item.lower():\n",
    "            print(f\"Processing Healthy folder: {item}\")\n",
    "            for filename in os.listdir(item_path):\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "                    filepaths.append(os.path.join(item_path, filename))\n",
    "                    labels.append('Healthy')\n",
    "                    \n",
    "        # --- CASE B: The 'Tumour' Folder (Anything that isn't Healthy) ---\n",
    "        else:\n",
    "            print(f\"Processing Tumour folder: {item}\")\n",
    "            for filename in os.listdir(item_path):\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "                    full_path = os.path.join(item_path, filename)\n",
    "                    name_lower = filename.lower()\n",
    "                    \n",
    "                    # Determine Subtype based on filename\n",
    "                    if 'glioma' in name_lower:\n",
    "                        label = 'Glioma'\n",
    "                    elif 'meningioma' in name_lower:\n",
    "                        label = 'Meningioma'\n",
    "                    elif 'pituitary' in name_lower:\n",
    "                        label = 'Pituitary'\n",
    "                    else:\n",
    "                        label = 'Tumor (Unspecified)' \n",
    "                    \n",
    "                    filepaths.append(full_path)\n",
    "                    labels.append(label)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "\n",
    "# Check results\n",
    "print(f\"Total images found: {len(df)}\")\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 2.2 Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split: 80% Train, 20% Test (using stratify to keep classes balanced)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42, stratify=df['label'])\n",
    "\n",
    "# 3. Split Train again to get Validation set (e.g. 10% of total)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.125, shuffle=True, random_state=42, stratify=train_df['label'])\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Val size:   {len(val_df)}\")\n",
    "print(f\"Test size:  {len(test_df)}\")\n",
    "\n",
    "# 4. Visualize to confirm labels are correct\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Get a random sample to check\n",
    "sample_df = df.sample(10)\n",
    "\n",
    "for i, (index, row) in enumerate(sample_df.iterrows()):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    img = mpimg.imread(row['filepath'])\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"{row['label']}\\n{os.path.basename(row['filepath'])[:10]}...\", fontsize=9) # Show label + part of filename\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### 2.3 Build Keras generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Images to correct format\n",
    "\n",
    "# 1. Define image size and batch size\n",
    "IMG_SIZE = (256, 256) \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 2. Create ImageDataGenerators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen   = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 3. Build generators FROM DATAFRAMES\n",
    "train_gen = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 3. Custom Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The Convolutional Neural Network (CNN) model designed for this project consists of four convolutional blocks followed by a final block with pooling, dropout and fully connected layers. Each convolutional block has a convolution layer, batch normalization, activation function (ReLU) and max pooling. Early stopping was added to control for overfitting and underfitting. Batch normalization was used to improve training speed and stability. Dropout was included in the final block to further prevent overfitting. The model was compiled with the Adam optimizer, categorical cross-entropy loss function, and accuracy as the evaluation metric.\n",
    "\n",
    "<br>\n",
    "\n",
    "### 3.1 CNN Architecture\n",
    "\n",
    "**Input and Data Augmentation**\n",
    "- Input layer: shape (256, 256, 1)\n",
    "- Data Augmentation: Random rotations and horizontal flips\n",
    "\n",
    "**First Convolutional Block**\n",
    "- Conv2d layer: 32 filters, 3x3 kernel, stride of 1, same padding\n",
    "- Batch Normalization\n",
    "- ReLU Activation\n",
    "- MaxPooling2d layer: 2x2 pool size, stride of 2.\n",
    "\n",
    "**Other Convolutional Blocks**\n",
    "- same as the first block but with increasing number of filters (64, 128, 256)\n",
    "\n",
    "**Classifier Head**\n",
    "- Global Average Pooling layer\n",
    "- Dense layer: 64 units, ReLU activation\n",
    "- Dropout layer: 0.3 dropout rate\n",
    "- Dense layer: 5 units (nÂº of classes), Softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN Architecture\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Custom CNN\n",
    "CNN = keras.Sequential([\n",
    "    \n",
    "    # Input\n",
    "    layers.InputLayer(shape=[256, 256, 1]),\n",
    "    \n",
    "    # Data Augmentation\n",
    "    layers.RandomFlip(\"horizontal\"), # flip images horizontally\n",
    "    layers.RandomRotation(0.1),      # rotate images randomly by 10%\n",
    "\n",
    "\n",
    "    # First Convolutional Block\n",
    "    layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # Fourth Convolutional Block\n",
    "    layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # Fifth Convolutional Block\n",
    "    layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.SpatialDropout2D(0.2),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # Sixth Convolutional Block\n",
    "    layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.SpatialDropout2D(0.2),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # Classifier Head\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(units=128),\n",
    "    layers.Dense(units=64),\n",
    "    layers.Dense(units=5, activation='softmax')  # 5 classes\n",
    "])\n",
    "\n",
    "CNN.summary()\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "CNN.compile(\n",
    "    optimizer = Adam(0.001),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### 3.2 Define class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class counts\n",
    "class_counts = np.array([2000, 1112, 672, 629, 587]) \n",
    "\n",
    "# Use sklearn's utility function to calculate balanced weights\n",
    "# This function calculates weights inversely proportional to class frequencies.\n",
    "weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(np.arange(len(class_counts))), # [0, 1, 2, 3, 4]\n",
    "    y=np.repeat(np.arange(len(class_counts)), class_counts) # Create a pseudo-y list for the counts\n",
    ")\n",
    "\n",
    "# Convert to dictionary format for Keras\n",
    "class_weight_dict = dict(enumerate(weights))\n",
    "print(\"Class Weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 3.3 Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta = 0.001,\n",
    "    patience = 10,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "hist_CNN = CNN.fit(\n",
    "    train_gen,\n",
    "    validation_data = val_gen,\n",
    "    batch_size = 32,\n",
    "    epochs = 20,\n",
    "    callbacks = [early_stopping],\n",
    "    class_weight = class_weight_dict,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "# Loss\n",
    "plt.plot(hist_CNN.history['loss'], label='train_loss')\n",
    "plt.plot(hist_CNN.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "plt.plot(hist_CNN.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(hist_CNN.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 2.2 Pre-trained Residual Network\n",
    "Charlotte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### **ResNet without finetuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "#### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_c5_, ds_val_c5_ = image_dataset_from_directory(\n",
    "    '/tmp/BrainTumorDataset',\n",
    "    validation_split=0.2,\n",
    "    subset='both',\n",
    "    seed=42,\n",
    "    image_size=(224,224),\n",
    "    batch_size=32,\n",
    "    label_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "ds_train_c5 = ds_train_c5_.map(preprocess)\n",
    "ds_val_c5 = ds_val_c5_.map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "#### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "def augment(image, label):\n",
    "    image = data_augmentation(image)\n",
    "    return image, label\n",
    "\n",
    "ds_train_c5 = ds_train_c5_.map(augment).map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "## pretrained base\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "base_model.trainable = False   # Freeze weights\n",
    "\n",
    "## attach head\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_c5 = model.fit(\n",
    "    ds_train_c5,\n",
    "    validation_data=ds_val_c5,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "#### Visualizing the loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # Loss\n",
    "# plt.plot(history_c5.history['loss'], label='train_loss')\n",
    "# plt.plot(history_c5.history['val_loss'], label='val_loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Accuracy\n",
    "# plt.plot(history_c5.history['accuracy'], label='train_accuracy')\n",
    "# plt.plot(history_c5.history['val_accuracy'], label='val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "#### **ResNet with finetuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze the first 140 layers \"freeze\"\n",
    "for layer in base_model.layers[:140]:\n",
    "    layer.trainable = False\n",
    "\n",
    "## attach head\n",
    "model_finetuned = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model_finetuned.compile(\n",
    "    optimizer=Adam(1e-5),    \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_c5_finetune = model_finetuned.fit(\n",
    "    ds_train_c5,\n",
    "    validation_data=ds_val_c5,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "#### Visualizing the loss and accuracy after fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "# plt.plot(history_c5_finetune.history['loss'], label='train_loss')\n",
    "# plt.plot(history_c5_finetune.history['val_loss'], label='val_loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Accuracy\n",
    "# plt.plot(history_c5_finetune.history['accuracy'], label='train_accuracy')\n",
    "# plt.plot(history_c5_finetune.history['val_accuracy'], label='val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## 2.3 Pre-trained Vision Transformer\n",
    "Jiazhen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ensure we know the number of classes (should be 5)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# 2. Load the ViT Base Model (86M Parameters)\n",
    "model_id = \"google/vit-base-patch16-224\"\n",
    "\n",
    "model = TFAutoModelForImageClassification.from_pretrained(\n",
    "    model_id, \n",
    "    num_labels=num_classes, \n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# 3. Define Optimizer and Loss (Using tf_keras to avoid version errors)\n",
    "# ViT requires a small learning rate (5e-5)\n",
    "optimizer = Adam(learning_rate=5e-5)\n",
    "loss = CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# 4. Compile the model\n",
    "# jit_compile=True will help speed up this heavy model on the GPU\n",
    "model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss=loss, \n",
    "    metrics=['accuracy'],\n",
    "    jit_compile=True \n",
    ")\n",
    "\n",
    "print(f\"Successfully loaded and compiled {model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup Generators with 'channels_first'\n",
    "# We add data_format='channels_first' to match the Hugging Face ViT requirements\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1,\n",
    "    data_format='channels_first'  # <--- THIS IS THE KEY FIX\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    data_format='channels_first'  # <--- THIS IS THE KEY FIX\n",
    ")\n",
    "\n",
    "# 2. Flow from DataFrame\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Generators recreated with Channels First format.\")\n",
    "\n",
    "# 3. Now run the training code again\n",
    "\n",
    "early_stopping = tf_keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=3, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10, \n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the Backbone \n",
    "backbone = TFViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "backbone.trainable = True \n",
    "\n",
    "# 2. Create Input (Channels First)\n",
    "inputs = Input(shape=(3, 224, 224), name=\"input_image\")\n",
    "\n",
    "# 3. Backbone Inference\n",
    "x = backbone(inputs).last_hidden_state\n",
    "x = x[:, 0, :] # Extract CLS Token\n",
    "\n",
    "# 4. Custom Hidden Layers\n",
    "x = layers.Dense(512, activation='relu', name=\"hidden_layer_1\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Dense(256, activation='relu', name=\"hidden_layer_2\")(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# 5. Output Layer\n",
    "outputs = layers.Dense(num_classes, name=\"prediction_head\")(x)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CHANGE IS HERE: distinct variable name and model name\n",
    "# ---------------------------------------------------------\n",
    "fine_tuned_model = Model(inputs=inputs, outputs=outputs, name=\"ViT_With_Custom_Head\")\n",
    "\n",
    "# 6. Compile\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "loss = CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "fine_tuned_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Verify the name in the summary\n",
    "fine_tuned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_custom = fine_tuned_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10, \n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
