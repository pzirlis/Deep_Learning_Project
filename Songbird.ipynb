{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0576f7e7",
   "metadata": {},
   "source": [
    "# Deep Learning Project\n",
    "\n",
    "**Group:** Songbird  \n",
    "**Members:** Charlotte de Vries, Jiazhen Tang, Paulo Zirlis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49aa099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup block (packages)\n",
    "import numpy as np\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a25a0",
   "metadata": {},
   "source": [
    "## 1. Project Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d911f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd88b15",
   "metadata": {},
   "source": [
    "## 2. Dataset Description\n",
    "\n",
    "The dataset includes high-resolution CT and MRI images captured from multiple patients, with each image labeled with the corresponding tumor type (e.g., glioma, meningioma, etc.). For this project we will focus solely on the **MRI** images for simplicity. The dataset's creator collected these data from different sources to assist researchers and healthcare professionals in developing AI models for the automatic detection, classification, and segmentation of brain tumors.\n",
    "\n",
    "The images are divided as follows:\n",
    "- Healty images: 2000\n",
    "- Tumor images: 3000\n",
    "    - Glioma: \n",
    "    - Meningioma: \n",
    "    - Pituitary: \n",
    "    - Tumor: \n",
    "- **Total of images:** 5000\n",
    "\n",
    "Source: [Brain tumor multimodal image (Kaggle)](https://www.kaggle.com/datasets/murtozalikhon/brain-tumor-multimodal-image-ct-and-mri/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d54f74",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d75893",
   "metadata": {},
   "source": [
    "## 2. Neural Network Models\n",
    "\n",
    "### 2.1 Custom CNN\n",
    "\n",
    "The Convolutional Neural Network (CNN) model designed for this project consists of four convolutional blocks followed by a final block with pooling, dropout and fully connected layers. Each convolutional block has a convolution layer, batch normalization, activation function (ReLU) and max pooling. Early stopping was added to control for overfitting and underfitting. Batch normalization was used to improve training speed and stability. Dropout was included in the final block to further prevent overfitting. The model was compiled with the Adam optimizer, categorical cross-entropy loss function, and accuracy as the evaluation metric.\n",
    "\n",
    "<br>\n",
    "\n",
    "The architecture is as follows:\n",
    "\n",
    "**Input and Data Augmentation**\n",
    "- Input layer: shape (256, 256, 1)\n",
    "- Data Augmentation: Random rotations and horizontal flips\n",
    "\n",
    "**First Convolutional Block**\n",
    "- Conv2d layer: 32 filters, 3x3 kernel, stride of 1, same padding\n",
    "- Batch Normalization\n",
    "- ReLU Activation\n",
    "- MaxPooling2d layer: 2x2 pool size, stride of 2.\n",
    "\n",
    "**Other Convolutional Blocks**\n",
    "- same as the first block but with increasing number of filters (64, 128, 256)\n",
    "\n",
    "**Classifier Head**\n",
    "- Global Average Pooling layer\n",
    "- Dense layer: 64 units, ReLU activation\n",
    "- Dropout layer: 0.3 dropout rate\n",
    "- Dense layer: 5 units (nÂº of classes), Softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN Architecture\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Custom CNN\n",
    "CNN = keras.Sequential([\n",
    "    \n",
    "    # Input\n",
    "    layers.InputLayer(shape=[256, 256, 1]),\n",
    "    \n",
    "    # Data Augmentation\n",
    "    layers.RandomFlip(\"horizontal\"), # flip images horizontally\n",
    "    layers.RandomRotation(0.1),      # rotate images randomly by 10%\n",
    "\n",
    "\n",
    "    # First Convolutional Block\n",
    "    layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # Fourth Convolutional Block\n",
    "    layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # Classifier Head\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(units=64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(units=5, activation='softmax')  # 5 classes\n",
    "])\n",
    "\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and Evaluate CNN\n",
    "\n",
    "# Compile the model\n",
    "CNN.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta = 0.001,\n",
    "    patience = 20,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "history = CNN.fit(\n",
    "    train,\n",
    "    validation_data = valid,\n",
    "    batch_size = 32,\n",
    "    epochs = 25,\n",
    "    callbacks = [early_stopping],\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "### ADD EVALUATION METRICS AND VISUALIZATIONS HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d289f3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e215ed71",
   "metadata": {},
   "source": [
    "## 2.2 Pre-trained Residual Network\n",
    "Charlotte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f4d97",
   "metadata": {},
   "source": [
    "#### **ResNet without finetuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532149c5",
   "metadata": {},
   "source": [
    "#### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_c5_, ds_val_c5_ = image_dataset_from_directory(\n",
    "    '/tmp/BrainTumorDataset',\n",
    "    validation_split=0.2,\n",
    "    subset='both',\n",
    "    seed=42,\n",
    "    image_size=(224,224),\n",
    "    batch_size=32,\n",
    "    label_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad52c68b",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc6856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "ds_train_c5 = ds_train_c5_.map(preprocess)\n",
    "ds_val_c5 = ds_val_c5_.map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6a79c1",
   "metadata": {},
   "source": [
    "#### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a4922",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "def augment(image, label):\n",
    "    image = data_augmentation(image)\n",
    "    return image, label\n",
    "\n",
    "ds_train_c5 = ds_train_c5_.map(augment).map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b96ca44",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7f4605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "## pretrained base\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "base_model.trainable = False   # Freeze weights\n",
    "\n",
    "## attach head\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44af3f85",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4007a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_c5 = model.fit(\n",
    "    ds_train_c5,\n",
    "    validation_data=ds_val_c5,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c35e5e",
   "metadata": {},
   "source": [
    "#### Visualizing the loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed25e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # Loss\n",
    "# plt.plot(history_c5.history['loss'], label='train_loss')\n",
    "# plt.plot(history_c5.history['val_loss'], label='val_loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Accuracy\n",
    "# plt.plot(history_c5.history['accuracy'], label='train_accuracy')\n",
    "# plt.plot(history_c5.history['val_accuracy'], label='val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b433ed",
   "metadata": {},
   "source": [
    "#### **ResNet with finetuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc97247",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze the first 140 layers \"freeze\"\n",
    "for layer in base_model.layers[:140]:\n",
    "    layer.trainable = False\n",
    "\n",
    "## attach head\n",
    "model_finetuned = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a4bd2",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model_finetuned.compile(\n",
    "    optimizer=Adam(1e-5),    \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_c5_finetune = model_finetuned.fit(\n",
    "    ds_train_c5,\n",
    "    validation_data=ds_val_c5,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c857aad0",
   "metadata": {},
   "source": [
    "#### Visualizing the loss and accuracy after fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "# plt.plot(history_c5_finetune.history['loss'], label='train_loss')\n",
    "# plt.plot(history_c5_finetune.history['val_loss'], label='val_loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Accuracy\n",
    "# plt.plot(history_c5_finetune.history['accuracy'], label='train_accuracy')\n",
    "# plt.plot(history_c5_finetune.history['val_accuracy'], label='val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7929142",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b1086",
   "metadata": {},
   "source": [
    "## 2.3 Pre-trained Vision Transformer\n",
    "Jiazhen"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
