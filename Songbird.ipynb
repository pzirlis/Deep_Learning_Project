{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Deep Learning Project\n",
    "\n",
    "**Group:** Songbird  \n",
    "**Members:** Charlotte de Vries, Jiazhen Tang, Paulo Zirlis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup block\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from transformers import TFAutoModelForImageClassification\n",
    "from sklearn.utils import class_weight, resample\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setup timer\n",
    "class ConvergenceTimer(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        print(\"Training started...\")\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        self.end_time = time.time()\n",
    "        self.total_time = self.end_time - self.start_time\n",
    "        print(f\"\\nTraining finished.\")\n",
    "        print(f\"Time to converge: {self.total_time:.2f} seconds ({self.total_time/60:.2f} minutes)\")\n",
    "\n",
    "\n",
    "print(\"Setup OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### 1.1 Objective*\n",
    "\n",
    "Apply different deep learning architectures to the visual classification task of identifying brain tumors in MRI images and compare them based on accuracy and time to converge.\n",
    "\n",
    "\n",
    "### 1.2 Neural Network Architectures\n",
    "\n",
    "We will implement and compare the following architectures:\n",
    "- Custom Convolutional Neural Network (CNN) with keras sequential\n",
    "- Custom Residual Network (ResNet)\n",
    "- Pre-trained Residual Network (ResNet50)\n",
    "- Pre-trained Residual Network (ResNet50) with fine-tuning\n",
    "- Pre-trained Visual Transformer (ViT)\n",
    "- Pre-trained Visual Transformer (ViT) with fine-tuning\n",
    "\n",
    "\n",
    "### 1.3 Dataset Description\n",
    "\n",
    "The dataset includes high-resolution CT and MRI images captured from multiple patients, with each image labeled with the corresponding tumor type (e.g., glioma, meningioma, etc.). For this project we will focus solely on the **MRI** images for simplicity. The dataset's creator collected these data from different sources to assist researchers and healthcare professionals in developing AI models for the automatic detection, classification, and segmentation of brain tumors.\n",
    "\n",
    "The images are divided as follows:\n",
    "- Healty images: 2000\n",
    "- Tumor images: 3000\n",
    "    - Meningioma: 1112\n",
    "    - Glioma: 672\n",
    "    - Pituitary: 629\n",
    "    - Tumor: 587\n",
    "- **Total of images:** 5000\n",
    "\n",
    "Source: [Brain tumor multimodal image (Kaggle)](https://www.kaggle.com/datasets/murtozalikhon/brain-tumor-multimodal-image-ct-and-mri/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 2.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "# 1. SETUP PATHS\n",
    "dataset_path = 'Data/Brain Tumor MRI images'\n",
    "\n",
    "print(f\"Checking contents of: {dataset_path}\")\n",
    "try:\n",
    "    items = os.listdir(dataset_path)\n",
    "    print(\"Found these items:\", items)\n",
    "except:\n",
    "    print(\"Error: The dataset_path does not exist.\")\n",
    "\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "\n",
    "# Get list of all folders in the main directory\n",
    "all_items = os.listdir(dataset_path)\n",
    "\n",
    "for item in all_items:\n",
    "    item_path = os.path.join(dataset_path, item)\n",
    "    \n",
    "    # We only care if it's a folder (directory)\n",
    "    if os.path.isdir(item_path):\n",
    "        \n",
    "        # --- CASE A: The 'Healthy' Folder ---\n",
    "        if 'healthy' in item.lower():\n",
    "            print(f\"Processing Healthy folder: {item}\")\n",
    "            for filename in os.listdir(item_path):\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "                    filepaths.append(os.path.join(item_path, filename))\n",
    "                    labels.append('Healthy')\n",
    "                    \n",
    "        # --- CASE B: The 'Tumour' Folder (Anything that isn't Healthy) ---\n",
    "        else:\n",
    "            print(f\"Processing Tumour folder: {item}\")\n",
    "            for filename in os.listdir(item_path):\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "                    full_path = os.path.join(item_path, filename)\n",
    "                    name_lower = filename.lower()\n",
    "                    \n",
    "                    # Determine Subtype based on filename\n",
    "                    if 'glioma' in name_lower:\n",
    "                        label = 'Glioma'\n",
    "                    elif 'meningioma' in name_lower:\n",
    "                        label = 'Meningioma'\n",
    "                    elif 'pituitary' in name_lower:\n",
    "                        label = 'Pituitary'\n",
    "                    else:\n",
    "                        label = 'Tumor (Unspecified)' \n",
    "                    \n",
    "                    filepaths.append(full_path)\n",
    "                    labels.append(label)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "\n",
    "# Check results\n",
    "print(f\"Total images found: {len(df)}\")\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 2.2 Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identify the majority class count\n",
    "max_count = df['label'].value_counts().max()\n",
    "print(f\"Target count per class: {max_count}\")\n",
    "\n",
    "# 2. Separate the dataframe by class\n",
    "groups = df.groupby('label')\n",
    "\n",
    "# 3. Create a list to hold the balanced dataframes\n",
    "balanced_dfs = []\n",
    "\n",
    "for label, group_df in groups:\n",
    "    # If this group is smaller than the max, oversample it\n",
    "    if len(group_df) < max_count:\n",
    "        \n",
    "        # Resample logic:\n",
    "        # replace=True: This allows duplication (essential for oversampling)\n",
    "        # n_samples=max_count: Target number of samples\n",
    "        oversampled_group = resample(group_df, \n",
    "                                     replace=True, \n",
    "                                     n_samples=max_count, \n",
    "                                     random_state=42)\n",
    "        balanced_dfs.append(oversampled_group)\n",
    "        print(f\"Oversampled {label} from {len(group_df)} to {len(oversampled_group)}\")\n",
    "        \n",
    "    else:\n",
    "        # If it's the majority class (Healthy), just keep it as is\n",
    "        balanced_dfs.append(group_df)\n",
    "        print(f\"Kept {label} at {len(group_df)}\")\n",
    "\n",
    "# 4. Concatenate all back into one DataFrame\n",
    "df_balanced = pd.concat(balanced_dfs).reset_index(drop=True)\n",
    "\n",
    "# 5. Shuffle the dataset so classes aren't clustered together\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 6. Verify the new counts\n",
    "print(\"\\nNew Label Distribution:\")\n",
    "print(df_balanced['label'].value_counts())\n",
    "\n",
    "# 7. Update your main df variable\n",
    "df = df_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### 2.3 Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split: 80% Train, 20% Test (using stratify to keep classes balanced)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42, stratify=df['label'])\n",
    "\n",
    "# 3. Split Train again to get Validation set (e.g. 10% of total)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.125, shuffle=True, random_state=42, stratify=train_df['label'])\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Val size:   {len(val_df)}\")\n",
    "print(f\"Test size:  {len(test_df)}\")\n",
    "\n",
    "# 4. Visualize to confirm labels are correct\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Get a random sample to check\n",
    "sample_df = df.sample(10)\n",
    "\n",
    "for i, (index, row) in enumerate(sample_df.iterrows()):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    img = mpimg.imread(row['filepath'])\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"{row['label']}\\n{os.path.basename(row['filepath'])[:10]}...\", fontsize=9) # Show label + part of filename\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### 2.4 Build Keras generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Images to correct format\n",
    "\n",
    "# 1. Define image size and batch size\n",
    "IMG_SIZE = (256, 256) \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 2. Create ImageDataGenerators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen   = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 3. Build generators FROM DATAFRAMES\n",
    "train_gen = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 3. Custom Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The Convolutional Neural Network (CNN) model designed for this project consists of four convolutional blocks followed by a final block with pooling, dropout and fully connected layers. Each convolutional block has a convolution layer, batch normalization, activation function (ReLU) and max pooling. Early stopping was added to control for overfitting and underfitting. Batch normalization was used to improve training speed and stability. Dropout was included in the final block to further prevent overfitting. The model was compiled with the Adam optimizer, categorical cross-entropy loss function, and accuracy as the evaluation metric.\n",
    "\n",
    "<br>\n",
    "\n",
    "### 3.1 CNN Architecture\n",
    "\n",
    "**Input and Data Augmentation**\n",
    "- Input layer: shape (256, 256, 1)\n",
    "- Data Augmentation: Random rotations and horizontal flips\n",
    "\n",
    "**First Convolutional Block**\n",
    "- Conv2d layer: 32 filters, 3x3 kernel, stride of 1, same padding\n",
    "- Batch Normalization\n",
    "- ReLU Activation\n",
    "- MaxPooling2d layer: 2x2 pool size, stride of 2.\n",
    "\n",
    "**Other Convolutional Blocks**\n",
    "- same as the first block but with increasing number of filters (64, 128, 256)\n",
    "\n",
    "**Classifier Head**\n",
    "- Global Average Pooling layer\n",
    "- Dense layer: 64 units, ReLU activation\n",
    "- Dropout layer: 0.3 dropout rate\n",
    "- Dense layer: 5 units (nÂº of classes), Softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN Architecture\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Custom CNN\n",
    "CNN = keras.Sequential([\n",
    "    \n",
    "    # Input\n",
    "    layers.InputLayer(shape=[256, 256, 1]),\n",
    "    \n",
    "    # Data Augmentation\n",
    "    layers.RandomFlip(\"horizontal\"), # flip images horizontally\n",
    "    layers.RandomRotation(0.1),      # rotate images randomly by 10%\n",
    "\n",
    "\n",
    "    # 1st Convolutional Block\n",
    "    layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # 2nd Convolutional Block\n",
    "    layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # 3rd Convolutional Block\n",
    "    layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # 4th Convolutional Block\n",
    "    layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # 5th Convolutional Block\n",
    "    layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.SpatialDropout2D(0.2),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # 6th Convolutional Block\n",
    "    layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.SpatialDropout2D(0.2),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    # Classifier Head\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(units=128),\n",
    "    layers.Dense(units=64),\n",
    "    layers.Dense(units=5, activation='softmax')  # 5 classes\n",
    "])\n",
    "\n",
    "CNN.summary()\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "CNN.compile(\n",
    "    optimizer = Adam(0.001),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 3.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ============== Callbacks ==============\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta = 0.001,\n",
    "    patience = 15,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "# Reduce LR on plateau\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,       # Reduce LR by 80% when stuck\n",
    "    patience=5,       # Wait 5 epochs before reducing\n",
    "    min_lr=1e-6,      \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_CNN.keras',    # Naming the file\n",
    "    monitor='val_accuracy',       # What to monitor\n",
    "    mode='max',                   # 'max' for accuracy, 'min' for loss\n",
    "    save_best_only=True,          \n",
    "    verbose=0                     # Print a message when saving\n",
    ")\n",
    "\n",
    "# Timer\n",
    "callback_timer = ConvergenceTimer()\n",
    "\n",
    "\n",
    "\n",
    "### ============== Training ==============\n",
    "\n",
    "# Fit the model\n",
    "hist_CNN = CNN.fit(\n",
    "    train_gen,\n",
    "    validation_data = val_gen,\n",
    "    batch_size = 32,\n",
    "    epochs = 50,\n",
    "    callbacks = [early_stopping, lr_scheduler, checkpoint, callback_timer],\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### 3.3 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ============== Evaluation ==============\n",
    "\n",
    "# Loss\n",
    "plt.plot(hist_CNN.history['loss'], label='train_loss')\n",
    "plt.plot(hist_CNN.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "plt.plot(hist_CNN.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(hist_CNN.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## 4. Pre-trained Residual Network\n",
    "Charlotte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### 4.1 ResNet **without finetuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "#### 4.1.1 Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_c5_, ds_val_c5_ = image_dataset_from_directory(\n",
    "    '/tmp/BrainTumorDataset',\n",
    "    validation_split=0.2,\n",
    "    subset='both',\n",
    "    seed=42,\n",
    "    image_size=(224,224),\n",
    "    batch_size=32,\n",
    "    label_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "#### 4.1.2 Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "ds_train_c5 = ds_train_c5_.map(preprocess)\n",
    "ds_val_c5 = ds_val_c5_.map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "#### 4.1.3 Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "def augment(image, label):\n",
    "    image = data_augmentation(image)\n",
    "    return image, label\n",
    "\n",
    "ds_train_c5 = ds_train_c5_.map(augment).map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "#### 4.1.4 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "## pretrained base\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "base_model.trainable = False   # Freeze weights\n",
    "\n",
    "## attach head\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "#### 4.1.5 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_c5 = model.fit(\n",
    "    ds_train_c5,\n",
    "    validation_data=ds_val_c5,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "#### 4.1.6 Visualizing the loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # Loss\n",
    "# plt.plot(history_c5.history['loss'], label='train_loss')\n",
    "# plt.plot(history_c5.history['val_loss'], label='val_loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Accuracy\n",
    "# plt.plot(history_c5.history['accuracy'], label='train_accuracy')\n",
    "# plt.plot(history_c5.history['val_accuracy'], label='val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### 4.2 ResNet **with finetuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "#### 4.2.1 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze the first 140 layers \"freeze\"\n",
    "for layer in base_model.layers[:140]:\n",
    "    layer.trainable = False\n",
    "\n",
    "## attach head\n",
    "model_finetuned = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "#### 4.2.2 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model_finetuned.compile(\n",
    "    optimizer=Adam(1e-5),    \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_c5_finetune = model_finetuned.fit(\n",
    "    ds_train_c5,\n",
    "    validation_data=ds_val_c5,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "#### 4.2.3 Visualizing the loss and accuracy after fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "plt.plot(history_c5_finetune.history['loss'], label='train_loss')\n",
    "plt.plot(history_c5_finetune.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "plt.plot(history_c5_finetune.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history_c5_finetune.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## 5. Pre-trained Vision Transformer\n",
    "\n",
    "### 5.1 ViT **without finetuning**\n",
    "\n",
    "#### 5.1.1 Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup Generators with 'channels_first'\n",
    "# We add data_format='channels_first' to match the Hugging Face ViT requirements\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1,\n",
    "    data_format='channels_first'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    data_format='channels_first'\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Flow from DataFrame\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,  \n",
    "    data_format='channels_first'\n",
    ")\n",
    "\n",
    "print(\"Generators recreated with Channels First format.\")\n",
    "\n",
    "# 3. Now run the training code again\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=3, \n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "#### 5.1.2 Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ensure we know the number of classes (should be 5)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# 2. Load the ViT Base Model (86M Parameters)\n",
    "model_id = \"google/vit-base-patch16-224\"\n",
    "\n",
    "model = TFAutoModelForImageClassification.from_pretrained(\n",
    "    model_id, \n",
    "    num_labels=num_classes, \n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# 3. Define Optimizer and Loss (Using tf_keras to avoid version errors)\n",
    "# ViT requires a small learning rate (5e-5)\n",
    "optimizer = Adam(learning_rate=5e-5)\n",
    "loss = CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# 4. Compile the model\n",
    "# jit_compile=True will help speed up this heavy model on the GPU\n",
    "model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss=loss, \n",
    "    metrics=['accuracy'],\n",
    "    jit_compile=True \n",
    ")\n",
    "\n",
    "print(f\"Successfully loaded and compiled {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "#### 5.1.3 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ViT = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10, \n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### 5.2 ViT **with finetuning**\n",
    "\n",
    "#### 5.2.1 Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the Backbone \n",
    "backbone = TFViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "backbone.trainable = True \n",
    "\n",
    "# 2. Create Input (Channels First)\n",
    "inputs = Input(shape=(3, 224, 224), name=\"input_image\")\n",
    "\n",
    "# 3. Backbone Inference\n",
    "x = backbone(inputs).last_hidden_state\n",
    "x = x[:, 0, :] # Extract CLS Token\n",
    "\n",
    "# 4. Custom Hidden Layers\n",
    "x = layers.Dense(512, activation='relu', name=\"hidden_layer_1\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Dense(256, activation='relu', name=\"hidden_layer_2\")(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# 5. Output Layer\n",
    "outputs = layers.Dense(num_classes, name=\"prediction_head\")(x)\n",
    "\n",
    "# 6. Define the Model\n",
    "fine_tuned_vit = Model(inputs=inputs, outputs=outputs, name=\"ViT_With_Custom_Head\")\n",
    "\n",
    "# 7. Compile\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "loss = CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "fine_tuned_vit.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Verify the name in the summary\n",
    "fine_tuned_vit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_custom = fine_tuned_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10, \n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "### 6.? ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Predictions\n",
    "print(\"Generating predictions...\")\n",
    "# 'model' is the variable name used in your model.fit() call above\n",
    "raw_predictions = model.predict(test_generator)\n",
    "\n",
    "# Check if the model output is a Hugging Face object (TFSequenceClassifierOutput) or a standard Keras Tensor\n",
    "# TFAutoModelForImageClassification usually returns an object where .logits contains the data\n",
    "if hasattr(raw_predictions, 'logits'):\n",
    "    logits = raw_predictions.logits\n",
    "else:\n",
    "    logits = raw_predictions\n",
    "\n",
    "# Convert probabilities/logits to class indices (e.g., [0, 2, 4, 1...])\n",
    "y_pred = np.argmax(logits, axis=1)\n",
    "\n",
    "# Get the true labels from the generator\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get Class Names (e.g., 'Glioma', 'Healthy', etc.)\n",
    "# We sort the keys to ensure they match the index order (0, 1, 2...)\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# 2. Create the Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# 3. Plot the Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_labels, \n",
    "            yticklabels=class_labels)\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=15)\n",
    "plt.ylabel('Actual Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 4. Print Metrics\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for comparing all models"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
